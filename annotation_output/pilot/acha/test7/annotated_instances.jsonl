{"id": "Attention_Check_Factual_testing_testing_Verbal Abuse", "displayed_text": "This is an attention check. Please select \"Verbal Abuse\" in the last question (Q2). You may choose any option for the other questions.", "label_annotations": {"Q1. Nature of harm": {"Potential harm": "q1_potential"}, "Q1a. Type of harm": {"Physical harm": "q1a_physical"}, "Q1b. Severity of harm": {"5. Critical": "q1b_critical"}, "Q1c. Extent of harm": {"3. Moderate harm": "q1c_3"}, "Q1d. Reversibility of harm": {"5. Completely irreversible": "q1d_5"}, "Q1e. AI intentionality": {"2. Slightly intentional": "q1e_2"}, "Q1f. Initiator": {"The AI (Replika)": "q1f_ai"}, "Q1g. Responsibilities": {"The AI agent (Replika)": "2. Slightly responsible", "The user (human who interacted with the AI)": "2. Slightly responsible", "The developer team (e.g., prompt engineers, product designers)": "2. Slightly responsible", "The company/platform (i.e., Replika)": "2. Slightly responsible", "The underlying model provider (e.g., OpenAI)": "2. Slightly responsible", "The regulators or oversight bodies": "2. Slightly responsible", "Other (If no other parties are involved, please select ": "2. Slightly responsible"}, "Q2. Harmful behavior category": {"Physical aggression": "q2_physical_aggression"}}, "span_annotations": {}, "behavioral_data": {"time_string": "Time spent: 0d 0h 0m 27s "}}
